{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How Probability Calibration Works.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTUFWp3c82SPINVS5F1FJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhekiMabheka/Explore/blob/main/How_Probability_Calibration_Works.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Probability Calibration Works\n",
        "\n",
        "Probability calibration is the process of calibrating an ML model to return the true likelihood of an event. This is necessary when we need the probability of the event in question rather than its classification."
      ],
      "metadata": {
        "id": "9glbdL7ufoeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset of classification task with many redundant and few informative features\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import *\n",
        "np.random.seed(0)\n",
        "\n",
        "X, y = datasets.make_classification(n_samples=100000, n_features=20, n_informative=2, n_redundant=2)\n",
        "\n",
        "train_samples = 100\n",
        "X_train = X[:train_samples]\n",
        "X_test  = X[train_samples:]\n",
        "y_train = y[:train_samples]\n",
        "y_test  = y[train_samples:]\n",
        "\n",
        "model_rfc = RandomForestClassifier()\n",
        "model_rfc.fit(X_train, y_train)\n",
        "y_pred_rfc = model_rfc.predict(X_test)\n",
        "\n",
        "print('Random Forest Classification Report')\n",
        "print(classification_report(y_true = y_test, y_pred = y_pred_rfc))\n",
        "\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train, y_train)\n",
        "y_pred_lr = model_lr.predict(X_test)\n",
        "\n",
        "print('Logistic Regression Classification Report: ')\n",
        "print(classification_report(y_true = y_test, y_pred = y_pred_lr))"
      ],
      "metadata": {
        "id": "eKHkcvZLfq1x",
        "outputId": "4bb1c7c0-4b21-482c-de8f-407f73d9ccf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88     49904\n",
            "           1       0.85      0.92      0.89     49996\n",
            "\n",
            "    accuracy                           0.88     99900\n",
            "   macro avg       0.88      0.88      0.88     99900\n",
            "weighted avg       0.88      0.88      0.88     99900\n",
            "\n",
            "Logistic Regression Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84     49904\n",
            "           1       0.84      0.86      0.85     49996\n",
            "\n",
            "    accuracy                           0.84     99900\n",
            "   macro avg       0.85      0.84      0.84     99900\n",
            "weighted avg       0.85      0.84      0.84     99900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The random forest classifier (RFC) got an F1 score of 0.89, which is not bad. The logistic regression performed just a bit worse than RF with a score of 0.85. But how well calibrated are they?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YtqyFHlHhLpH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9YAJSZzgmBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}